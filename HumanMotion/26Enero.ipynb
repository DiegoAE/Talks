{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:e92a087e2f94473077f81858b74401609345f6e096fc06aeb32a615f985cb8e0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Estimation of model parameters."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Estimation of parameters related with the markovian dynamics of hidden states. This means assuming the emission parameters known and fixed.\n",
      "2. Jointly estimation of the model parameters including the emission parameters (i.e $A$, $s$ and LFM's hyperparameters)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Having $L$ realizations of the HMM to train, the log-likelihood of complete-data can be written as follows:\n",
      "\n",
      "$$ \\ln{p(Z, Y | X, \\Theta)} = \\sum_{t=1}^L \\left \\{ \\sum_{k=1}^K z_{1,k}^t \\ln{s_k} + \\sum_{n=2}^{W_t} \\sum_{j=1}^K \\sum_{k=1}^K  z_{n, j}^t z_{n - 1, k}^t \\ln{A_{j,k}} + \\sum_{n=1}^{W_t} \\sum_{k=1}^K z_{n,k}^t \\ln{p(Y_n^t |\\theta_k, X_n)} \\right \\}$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## 1. Estimation of $A$ and $s$ from multiple sequences via the EM algorithm."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Maximization with respect to the parameters $\\{A, s\\}$.\n",
      "\n",
      "$$ A_{j,k}  = \\frac{ \\sum_{t=1}^L \\sum_{n=2}^{W_t} \\varepsilon^t(z^t_{n - 1, j}, z^t_{n,k})}{ \\sum_{t=1}^L \\sum_{n=2}^{W_t} \\gamma^t(z^t_{n - 1, j}) }$$\n",
      "\n",
      "$$ s_k = \\frac{1}{L} \\sum_{t=1}^L \\gamma^t(z^t_{1,k})$$\n",
      "\n",
      "Where $\\varepsilon^t(.,.)$ and $\\gamma^t(.)$ denote the computed posteriors over the t-th training sequence.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## 1. Estimation of $A$ and $s$ from multiple sequences via the EM algorithm."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Toy using the estimated $A$ and $s$ and the Viterbi algorithm to determine the most probable hidden state sequence."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"viterbi_no_emission_params.png\" width=\"600\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### 1. Estimation of $A$ and $s$ from multiple sequences via the EM algorithm."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Estimated values for $A$ and $s$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial state distribution [ 0.34091363  0.30128767  0.3577987 ]\n",
      "hidden state transition matrix\n",
      "[[ 0.12550405  0.44757314  0.42692281]\n",
      " [ 0.54776779  0.09133728  0.36089493]\n",
      " [ 0.30702207  0.58407508  0.10890285]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Actual values for $A$ ans $s$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initial state distribution [ 0.3  0.3  0.4]\n",
      "hidden state transition matrix\n",
      "[[ 0.1  0.5  0.4]\n",
      " [ 0.6  0.1  0.3]\n",
      " [ 0.4  0.5  0.1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}